{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-label Keywords Extraction using Transformers(BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tvitlqHz3THw",
    "outputId": "feec4242-f232-41f4-b7a1-541d05cf5ca9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-transformers\n",
      "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
      "\u001b[K     |████████████████████████████████| 176 kB 15.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.9.0+cu102)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (2.23.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (4.62.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.19.5)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 87.3 MB/s \n",
      "\u001b[?25hCollecting boto3\n",
      "  Downloading boto3-1.18.21-py3-none-any.whl (131 kB)\n",
      "\u001b[K     |████████████████████████████████| 131 kB 77.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (2019.12.20)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
      "\u001b[K     |████████████████████████████████| 895 kB 61.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.7.4.3)\n",
      "Collecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting botocore<1.22.0,>=1.21.21\n",
      "  Downloading botocore-1.21.21-py3-none-any.whl (7.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.8 MB 47.6 MB/s \n",
      "\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n",
      "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
      "\u001b[K     |████████████████████████████████| 79 kB 8.8 MB/s \n",
      "\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n",
      "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
      "\u001b[K     |████████████████████████████████| 138 kB 68.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.21->boto3->pytorch-transformers) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.21->boto3->pytorch-transformers) (1.15.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (2021.5.30)\n",
      "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 65.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (2.10)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers) (1.0.1)\n",
      "Installing collected packages: urllib3, jmespath, botocore, s3transfer, sentencepiece, sacremoses, boto3, pytorch-transformers\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.24.3\n",
      "    Uninstalling urllib3-1.24.3:\n",
      "      Successfully uninstalled urllib3-1.24.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "Successfully installed boto3-1.18.21 botocore-1.21.21 jmespath-0.10.0 pytorch-transformers-1.2.0 s3transfer-0.5.0 sacremoses-0.0.45 sentencepiece-0.1.96 urllib3-1.25.11\n",
      "\u001b[K     |████████████████████████████████| 916 kB 16.6 MB/s \n",
      "\u001b[K     |████████████████████████████████| 829 kB 66.1 MB/s \n",
      "\u001b[K     |████████████████████████████████| 118 kB 82.4 MB/s \n",
      "\u001b[K     |████████████████████████████████| 272 kB 93.1 MB/s \n",
      "\u001b[K     |████████████████████████████████| 636 kB 78.2 MB/s \n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 73.1 MB/s \n",
      "\u001b[K     |████████████████████████████████| 142 kB 79.0 MB/s \n",
      "\u001b[K     |████████████████████████████████| 294 kB 81.0 MB/s \n",
      "\u001b[?25h  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[K     |████████████████████████████████| 2.6 MB 15.8 MB/s \n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 67.3 MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "! pip install pytorch-transformers\n",
    "! pip install -q pytorch-lightning\n",
    "! pip install -q bs4\n",
    "! pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FMD_2l79Z0MK"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import copy\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from google.colab import drive\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler, TensorDataset)\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from transformers import BertConfig,BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "from pytorch_transformers.optimization import AdamW, WarmupLinearSchedule\n",
    "import pytorch_lightning as pl\n",
    "from tqdm import tqdm_notebook, trange\n",
    "from transformers import BertModel,BertTokenizer\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "acXY5rkHOvsv"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dhrioSIkZPID",
    "outputId": "e45fa06e-c874-4359-f378-c9f06abe0828"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# mounting to google drive in order to access data in google colab\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WN7AoRQwtkK5"
   },
   "source": [
    "# Basic Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WLBMJPJt0G69",
    "outputId": "d5b2b676-22b2-4cf0-df43-b0220b04bac6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13203"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/content/drive/MyDrive/Final_Project_DL/sample_train.csv',encoding='latin-1',usecols=['Tags'])\n",
    "df['Tags']= df['Tags'].astype(str).apply(lambda x:re.sub(\"-\",\" \",x).split())\n",
    "tags = [item for sublist in df['Tags'].tolist() for item in sublist]\n",
    "# count of unique tags\n",
    "len(set(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "A8FUyG86pu4F",
    "outputId": "89f2e526-524f-465d-acf7-c644fff73fa4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEvCAYAAABCCKquAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO29d9gkRdW/f3/IOa9kWNAVRBReWJKiIkiU9KokFVZEMKCiqK9gAgG/ghnxB4oCAipRFAQRVoKgkpacZSUIK2FlAQmigJ/fH6d6n57ZibvPPhvm3Nc110xXVVdX93Sfrjp1zinZJkmSJBkc5pnVDUiSJElGlhT8SZIkA0YK/iRJkgEjBX+SJMmAkYI/SZJkwEjBnyRJMmCk4E9mGZJ+KOnLw1TXapKekzRv2b5S0oeGo+5S38WSxg1XfX0c9yhJ/5D02EgfO5l7UdrxJzMDSQ8CywMvA68AdwGnASfa/u901PUh27/vY58rgZ/Z/kk/xyr7Hg68xvb7+913OJG0GnAvsLrtJ1rkb0Gc4yoj3bZkziZ7/MnMZCfbiwOrA0cDnwdOGu6DSJpvuOucTVgNeLKV0E+SGSEFfzLTsf2M7QuAPYBxktYFkPRTSUeV38tJulDS05KmSLpa0jySTicE4G+KKuf/JI2WZEn7SfobcHktrf4SeLWk6yX9U9L5kpYpx9pC0iP1Nkp6UNI7JG0HfAHYoxzv1pI/VXVU2vUlSQ9JekLSaZKWLHlVO8ZJ+ltR03yx3bWRtGTZf3Kp70ul/ncA44GVSjt+2rTfosDFtfznJK0kaWNJ15Tr+KikH0haoLbfNpLulfSMpOMl/aF2Xq8p28+Udp/V51+dzCGk4E9GDNvXA48Ab2mR/ZmSN4pQEX0hdvHewN+I0cNitr9R2+dtwOuAbdscch/gg8CKhMrp+z208XfA/wPOKsdbr0WxD5TP24E1gcWAHzSV2RxYC9gK+Iqk17U55HHAkqWet5U271vUWtsDfy/t+EBTO59vyl/M9t8JtdqngeWAzcrxPwbxcgXOBQ4FliXUSG+qVXskcCmwNLBKaVsyF5KCPxlp/g4s0yL9JUJAr277JdtXu/sE1OG2n7f9rzb5p9u+owjJLwO7V5O/M8j7gO/Yvt/2c4Qg3bNptPFV2/+yfStwKzDNC6S0ZU/gUNvP2n4Q+Daw9/Q2zPaNtq+1/XKp70fECwVgB+BO2+fZrl6E9Unjlwi13Eq2X7T9x+ltRzJ7k4I/GWlWBqa0SP8mMBG4VNL9kg7poa6H+8h/CJif6AnPKCuV+up1z0eMVCrqAvUFYlTQzHKlTc11rTy9DZP02qIye0zSP4nRS3XOK1G7JuXFWld5/R8g4HpJd0r64PS2I5m9ScGfjBiSNiKE2jQ9ydLj/YztNYGdgYMlbVVlt6my24hg1drv1Yge7T+A54FFau2al1Ax9Vrv34mecb3ul4HHu+zXzD8Y6mXX65rU4/6t2nkCcA8wxvYShMpMJe9RQoUDgCTVt20/Znt/2ysBHwaOl/SaHtuSzEGk4E9mOpKWkLQjcCZhfnh7izI7lslFAc8QuurK7PNxQgfeL++XtI6kRYAjgHNtvwL8BVhI0jslzQ98CViwtt/jwGhJ7Z6PM4BPS1pD0mIMzQm83E/jSlvOBr4maXFJqwMHAz/rsYrHgWWrieXC4sA/geckrQ18tJZ3EfAGSbsWtdSBwApVpqTdJFUvgqeIF0tfprfJnEEK/mRm8htJzxLqhS8C3wH2bVN2DPB74DngGuB421eUvK8DXyqWKp/t4/inAz8l1C4LAZ+EsDIiJjx/QvSun6dR5XFO+X5S0k0t6j251H0V8ADwIvCJPtpV5xPl+PcTI6FflPq7Yvse4iV0f7k2KwGfBd4LPAv8GDirVv4fwG7AN4AngXWACcC/S5GNgOskPQdcABxk+/7pPK9kNiYduJJkQCkjmkeA99VesskAkD3+JBkgJG0raSlJCzKk/792FjcrGWFS8CfJYLEZ8FdiYnknYNcO5rDJXEqqepIkSQaM7PEnSZIMGLN1cKvlllvOo0ePntXNSJIkmaO48cYb/2F7VLv82Vrwjx49mgkTJszqZiRJksxRSHqoU36qepIkSQaMFPxJkiQDRgr+JEmSASMFf5IkyYCRgj9JkmTASMGfJEkyYKTgT5IkGTBS8CdJkgwYPQl+SZ8uS7HdIekMSQuVRSiukzRR0lmSFihlFyzbE0v+6Fo9h5b0eyW1WyA7SZIkmYl09dyVtDKxgMU6tv8l6WxigegdgO/aPlPSD4H9iGXf9gOesv0aSXsCxwB7SFqn7Pd6Yu3P30t6bVmFqCOjD7lomrQHj35nr+eYJEmS1OhV1TMfsHBZrm0RYu3OLYFzS/6pwK7l9y5lm5K/VVlObxfgTNv/tv0AsbD2xjN+CkmSJEk/dBX8ticB3wL+Rgj8Z4Abgadra4w+QiyiTfl+uOz7cim/bD29xT5JkiTJCNFV8Etamuitr0GoaBYFtptZDZJ0gKQJkiZMnjx5Zh0mSZJkYOlF1fMO4AHbk22/BJwHvBlYqqh+AFYhFq2mfK8KUPKXJBZ2npreYp+p2D7R9ljbY0eNahtVNEmSJJlOehH8fwM2lbRI0dVvBdwFXAG8p5QZB5xffl9Qtin5lzuW+boA2LNY/awBjAGuH57TSJIkSXqlq1WP7esknQvcBLwM3AycCFwEnCnpqJJ2UtnlJOB0SROBKYQlD7bvLBZBd5V6DuzFoidJkiQZXnpaiMX2YcBhTcn308Iqx/aLwG5t6vka8LU+25gkSZIMI+m5myRJMmCk4E+SJBkwUvAnSZIMGCn4kyRJBowU/EmSJANGCv4kSZIBIwV/kiTJgJGCP0mSZMBIwZ8kSTJgpOBPkiQZMFLwJ0mSDBgp+JMkSQaMFPxJkiQDRgr+JEmSAaOnsMxzAqMPuahh+8Gj3zmLWpIkSTJ7kz3+JEmSASMFf5IkyYDRVfBLWkvSLbXPPyV9StIyksZLuq98L13KS9L3JU2UdJukDWp1jSvl75M0rv1RkyRJkplFL2vu3gusDyBpXmAS8CvgEOAy20dLOqRsfx7YnlhIfQywCXACsImkZYjlG8cCBm6UdIHtp4b9rFqQcwBJkiRBv6qerYC/2n4I2AU4taSfCuxafu8CnObgWmApSSsC2wLjbU8pwn48sN0Mn0GSJEnSF/0K/j2BM8rv5W0/Wn4/Bixffq8MPFzb55GS1i69AUkHSJogacLkyZP7bF6SJEnSjZ4Fv6QFgJ2Bc5rzbJtQ38wwtk+0Pdb22FGjRg1HlUmSJEmNfnr82wM32X68bD9eVDiU7ydK+iRg1dp+q5S0dulJkiTJCNKP4N+LITUPwAVAZZkzDji/lr5Pse7ZFHimqIQuAbaRtHSxANqmpCVJkiQjSE+eu5IWBbYGPlxLPho4W9J+wEPA7iX9t8AOwETgBWBfANtTJB0J3FDKHWF7ygyfQZIkSdIXPQl+288DyzalPUlY+TSXNXBgm3pOBk7uv5lJkiTJcJGeu0mSJAPGXBOkbThIJ68kSQaB7PEnSZIMGCn4kyRJBowU/EmSJANGCv4kSZIBIwV/kiTJgJGCP0mSZMBIwZ8kSTJgpOBPkiQZMNKBqw/SwStJkrmBFPzDSL4YkiSZE0hVT5IkyYCRgj9JkmTASMGfJEkyYKTgT5IkGTB6EvySlpJ0rqR7JN0taTNJy0gaL+m+8r10KStJ35c0UdJtkjao1TOulL9P0rj2R0ySJElmFr32+I8Ffmd7bWA94G7gEOAy22OAy8o2xKLsY8rnAOAEAEnLAIcBmwAbA4dVL4skSZJk5Ogq+CUtCbwVOAnA9n9sPw3sApxaip0K7Fp+7wKc5uBaYClJKwLbAuNtT7H9FDAe2G5YzyZJkiTpSi89/jWAycApkm6W9JOy+Pryth8tZR4Dli+/VwYeru3/SElrl54kSZKMIL0I/vmADYATbP8P8DxDah1g6gLrHo4GSTpA0gRJEyZPnjwcVSZJkiQ1ehH8jwCP2L6ubJ9LvAgeLyocyvcTJX8SsGpt/1VKWrv0BmyfaHus7bGjRo3q51ySJEmSHugq+G0/Bjwsaa2StBVwF3ABUFnmjAPOL78vAPYp1j2bAs8UldAlwDaSli6TutuUtCRJkmQE6TVWzyeAn0taALgf2Jd4aZwtaT/gIWD3Uva3wA7AROCFUhbbUyQdCdxQyh1he8qwnEWSJEnSMz0Jftu3AGNbZG3VoqyBA9vUczJwcj8NTJIkSYaX9NxNkiQZMFLwJ0mSDBgp+JMkSQaMFPxJkiQDRgr+JEmSASMFf5IkyYCRgj9JkmTASMGfJEkyYKTgT5IkGTBS8CdJkgwYKfiTJEkGjBT8SZIkA0YK/iRJkgEjBX+SJMmAkYI/SZJkwEjBnyRJMmCk4E+SJBkwehL8kh6UdLukWyRNKGnLSBov6b7yvXRJl6TvS5oo6TZJG9TqGVfK3ydpXLvjJUmSJDOPfnr8b7e9vu1qCcZDgMtsjwEuK9sA2wNjyucA4ASIFwVwGLAJsDFwWPWySJIkSUaOGVH17AKcWn6fCuxaSz/NwbXAUpJWBLYFxtueYvspYDyw3QwcP0mSJJkOehX8Bi6VdKOkA0ra8rYfLb8fA5Yvv1cGHq7t+0hJa5fegKQDJE2QNGHy5Mk9Ni9JkiTplfl6LLe57UmSXgWMl3RPPdO2JXk4GmT7ROBEgLFjxw5LnbMTow+5qGH7waPfOYtakiTJoNJTj9/2pPL9BPArQkf/eFHhUL6fKMUnAavWdl+lpLVLT5IkSUaQroJf0qKSFq9+A9sAdwAXAJVlzjjg/PL7AmCfYt2zKfBMUQldAmwjaekyqbtNSUuSJElGkF5UPcsDv5JUlf+F7d9JugE4W9J+wEPA7qX8b4EdgInAC8C+ALanSDoSuKGUO8L2lGE7k7mEbqqg5vxWZZIkSTrRVfDbvh9Yr0X6k8BWLdINHNimrpOBk/tvZpIkSTJcpOdukiTJgJGCP0mSZMBIwZ8kSTJgpOBPkiQZMFLwJ0mSDBgp+JMkSQaMFPxJkiQDRgr+JEmSASMFf5IkyYCRgj9JkmTASMGfJEkyYKTgT5IkGTBS8CdJkgwYKfiTJEkGjBT8SZIkA0YK/iRJkgEjBX+SJMmA0bPglzSvpJslXVi215B0naSJks6StEBJX7BsTyz5o2t1HFrS75W07XCfTJIkSdKdfnr8BwF317aPAb5r+zXAU8B+JX0/4KmS/t1SDknrAHsCrwe2A46XNO+MNT9JkiTpl54Ev6RVgHcCPynbArYEzi1FTgV2Lb93KduU/K1K+V2AM23/2/YDxGLsGw/HSSRJkiS903Wx9cL3gP8DFi/bywJP2365bD8CrFx+rww8DGD7ZUnPlPIrA9fW6qzvMxVJBwAHAKy22mo9n0gyxOhDLmrYfvDod86iliRJMjvStccvaUfgCds3jkB7sH2i7bG2x44aNWokDpkkSTJQ9NLjfzOws6QdgIWAJYBjgaUkzVd6/asAk0r5ScCqwCOS5gOWBJ6spVfU90lGkBwRJMlg07XHb/tQ26vYHk1Mzl5u+33AFcB7SrFxwPnl9wVlm5J/uW2X9D2L1c8awBjg+mE7kyRJkqQnetXxt+LzwJmSjgJuBk4q6ScBp0uaCEwhXhbYvlPS2cBdwMvAgbZfmYHjJ0mSJNNBX4Lf9pXAleX3/bSwyrH9IrBbm/2/Bnyt30YmSZIkw0d67iZJkgwYKfiTJEkGjBT8SZIkA0YK/iRJkgFjRqx6krmUZjt/SFv/JJmbyB5/kiTJgJGCP0mSZMBIwZ8kSTJgpOBPkiQZMHJyN5kuMtBbksy5pOBPZgr5YkiS2ZdU9SRJkgwYKfiTJEkGjBT8SZIkA0bq+JNZRs4DJMmsIXv8SZIkA0Yvi60vJOl6SbdKulPSV0v6GpKukzRR0lmSFijpC5btiSV/dK2uQ0v6vZK2nVknlSRJkrSnlx7/v4Etba8HrA9sJ2lT4Bjgu7ZfAzwF7FfK7wc8VdK/W8ohaR1iGcbXA9sBx0uadzhPJkmSJOlOL4ut2/ZzZXP+8jGwJXBuST8V2LX83qVsU/K3kqSSfqbtf9t+AJhIi6UbkyRJkplLTzp+SfNKugV4AhgP/BV42vbLpcgjwMrl98rAwwAl/xlg2Xp6i33qxzpA0gRJEyZPntz/GSVJkiQd6cmqx/YrwPqSlgJ+Baw9sxpk+0TgRICxY8d6Zh0nmf1Jq58kmTn0Zc5p+2lJVwCbAUtJmq/06lcBJpVik4BVgUckzQcsCTxZS6+o75MkfdPLgjH58kiSaenFqmdU6ekjaWFga+Bu4ArgPaXYOOD88vuCsk3Jv9y2S/qexepnDWAMcP1wnUiSJEnSG730+FcETi0WOPMAZ9u+UNJdwJmSjgJuBk4q5U8CTpc0EZhCWPJg+05JZwN3AS8DBxYVUpIkSTKCdBX8tm8D/qdF+v20sMqx/SKwW5u6vgZ8rf9mJsnMoZsqKNcfTuZG0nM3SZJkwEjBnyRJMmCk4E+SJBkwUvAnSZIMGCn4kyRJBowU/EmSJANGCv4kSZIBIwV/kiTJgJGCP0mSZMBIwZ8kSTJgpOBPkiQZMPoKy5wkybRk6OdkTiN7/EmSJANG9viTZCbTy4ig3yihOapIZoTs8SdJkgwYKfiTJEkGjFT1JMlcQKqCkn7oZc3dVSVdIekuSXdKOqikLyNpvKT7yvfSJV2Svi9poqTbJG1Qq2tcKX+fpHHtjpkkSZLMPHpR9bwMfMb2OsCmwIGS1gEOAS6zPQa4rGwDbE8spD4GOAA4AeJFARwGbEIs2XhY9bJIkiRJRo6ugt/2o7ZvKr+fBe4GVgZ2AU4txU4Fdi2/dwFOc3AtsJSkFYFtgfG2p9h+ChgPbDesZ5MkSZJ0pa/JXUmjiYXXrwOWt/1oyXoMWL78Xhl4uLbbIyWtXXrzMQ6QNEHShMmTJ/fTvCRJkqQHep7clbQY8EvgU7b/KWlqnm1L8nA0yPaJwIkAY8eOHZY6kyTJCeBkiJ4Ev6T5CaH/c9vnleTHJa1o+9GiynmipE8CVq3tvkpJmwRs0ZR+5fQ3PUmS4SRfDINDL1Y9Ak4C7rb9nVrWBUBlmTMOOL+Wvk+x7tkUeKaohC4BtpG0dJnU3aakJUmSJCNILz3+NwN7A7dLuqWkfQE4Gjhb0n7AQ8DuJe+3wA7AROAFYF8A21MkHQncUModYXvKsJxFkiRJ0jNdBb/tPwJqk71Vi/IGDmxT18nAyf00MEmSJBle0nM3SZKeaJ4DgJwHmFPJWD1JkiQDRgr+JEmSASMFf5IkyYCRgj9JkmTASMGfJEkyYKRVT5Ikw8ZwLCGZHsQzn+zxJ0mSDBjZ40+SZI4iRwQzTgr+JEnmKvLF0J0U/EmSDBzDMRcxJ5OCP0mSpE/m9PAVObmbJEkyYKTgT5IkGTBS1ZMkSTITmJ3nCVLwJ0mSzAJm5Yuhq+CXdDKwI/CE7XVL2jLAWcBo4EFgd9tPlWUajyVW4HoB+IDtm8o+44AvlWqPsn3q8J5KkiTJ3EMvE8jT+/LoRcf/U2C7prRDgMtsjwEuK9sA2wNjyucA4ASY+qI4DNgE2Bg4rKy7myRJkowwXQW/7auA5rVxdwGqHvupwK619NMcXAssJWlFYFtgvO0ptp8CxjPtyyRJkiQZAabXqmd524+W348By5ffKwMP18o9UtLapU+DpAMkTZA0YfLkydPZvCRJkqQdM2zOWRZX9zC0parvRNtjbY8dNWrUcFWbJEmSFKZX8D9eVDiU7ydK+iRg1Vq5VUpau/QkSZJkhJlewX8BMK78HgecX0vfR8GmwDNFJXQJsI2kpcuk7jYlLUmSJBlhejHnPAPYAlhO0iOEdc7RwNmS9gMeAnYvxX9LmHJOJMw59wWwPUXSkcANpdwRtpsnjJMkSZIRoKvgt71Xm6ytWpQ1cGCbek4GTu6rdUmSJMmwk7F6kiRJBowU/EmSJANGCv4kSZIBIwV/kiTJgJGCP0mSZMBIwZ8kSTJgpOBPkiQZMFLwJ0mSDBgp+JMkSQaMFPxJkiQDRgr+JEmSASMFf5IkyYCRgj9JkmTASMGfJEkyYKTgT5IkGTBS8CdJkgwYKfiTJEkGjBEX/JK2k3SvpImSDhnp4ydJkgw6Iyr4Jc0L/H/A9sA6wF6S1hnJNiRJkgw6I93j3xiYaPt+2/8BzgR2GeE2JEmSDDSK9dFH6GDSe4DtbH+obO8NbGL747UyBwAHlM21gHubqlkO+EeHw8xofh5jeOuYW44xHHXMLccYjjryGDO3jtVtj2pb2vaIfYD3AD+pbe8N/KDPOibMzPw8xpzXzrwWeS3m5mMMVx31z0ireiYBq9a2VylpSZIkyQgx0oL/BmCMpDUkLQDsCVwwwm1IkiQZaOYbyYPZflnSx4FLgHmBk23f2Wc1J87k/DzG8NYxtxxjOOqYW44xHHXkMUa+jqmM6ORukiRJMutJz90kSZIBIwV/kiTJgJGCfxiQtJOkvJZJkswRzDXCStKrJK1WfYa57mO6pO0B3CfpG5LWblPHgr2kzSiS3tAl/1RJS9W2l5Z08nC3o8Px55X0rZE6XhJIWljSWm3yNpa0Ufm9jqSDJe0wHcdYQNK65TN/Lf2TklbttG+P9bd6hpaZ0XpHEklrzOo2wBwwuStpOdttPdYk7Qx8G1gJeAJYHbjb9uu73RS2p9TqWYEIKWHgBtuP1fJusr1B03Fvs/3G2vYSwF7AvqWOU4AzbD/boY6bbG8g6biyT7t2frKUfzNwi+3nJb0f2AA41vZDtTqvBhYEfgr83PYzTce82fb/9JD2+nYWV6UdhxPXej5A0UyvWSuzOTDG9imSRgGL2X6g5F1re9N251vK7Gb7nOY04Cu0vlZVG97Y6/9e6vud7WclfYm4nkfZvqnkLwi8GxhNzQLO9hFN16LtfyLptcAJwPK215X0RmBn20fV6jgd+Hj1X0lanbB426psvxp4xPa/JW0BvBE4zfbTJX9T4M7avbYE8Drb15XtnYBvAQvYXkPS+sARtneWdBgRO2s+YDywCXAFsDVhffevLtfyO+UYWwCnAg+W/2JVYJztqyQ9AzwP/BU4AzjH9uTmuiStCRwLbAb8F7gG+LTt+0v+RcCutl8q2ysCF9resFbHIsBngNVs7y9pDBEB4LW9nEetnp2Bt5bNP9j+TS3vHbZ/31R+nO1Ty++3Ao/bvrfcH5sRMukiSTfa3lDSZdX/21TPlrYvl/SuNu08r5Trel91YrYV/JLmsf3fusCUdJDtY5vK3QpsCfze9v9Iejvwftv7SXqAEBICVgOeKr+XAv5me41Sx4cIgXJ5yX8bcAQhQD8GrEnctBWLA3+y/f6mtixLeCN/CrgbeA3xArgE+Bnw3lI/wBLAD22vLWlcp2tRu6FuA9YjHvyfAj8Bdrf9tqZ2jAE+COwGXA+cYnt87XptYfupsr0McWO/oamOaV5Utbx7gE8DNwKv1Nr5ZMk/DBgLrGX7tZJWIh72N5f8E4CVgXMIgVDtf16n40u6CfjfLtfqoab/vUWReEFVL+/ykjoK+CbwFdublPzfAc+0OM9v19rU8T+R9Afgc8CPqperpDtsr1ur48Pleh5crsvngM9UwkbSLeV6jgZ+C5wPvN72DiX/ZmADl4e5qB0n1J6bG4ln5MpaG263/QZJtwPrE/f6Y8Aqtv8paWHgOuCXXa73V2vHeK/te8v2a4mOz4alfRsC7yBGxzuXa3oGcF7thXUtEcTxjFL9nsAnav/H/sAORASAVQkfoM/avrR2Lc8qde9TBOIiwJ+BX/VyHqWOrxOdwJ+XpL2IzuAXSv5VwJ3AZ4HFiP/837bfI+l7Zd/5iOd+K+BiQqbcXK7BOcBHge+2aMqStg+TdErrZvqDpQ1d76uO9OriO9If4Grgd8Dfge2IB+KmFuUmlO9bgXmq301lfgzsUNvevlywavteYNna9rIlbUniYTuD6N1Wn2Wa6t+FuLFuL3/Gq0r6IsBkogf1bPmuPucD7+rzmtxUvr8C7FdPa1F2XqK3Ool4Cd0DvAvYp/w+snzuAfZusf/NHdpxXZd23kII3ZtrabfVfp/S4nNy7b85Dngc+H7t81Pg+hbHWgJYpvr0eT1vLt9fJ4QWTW2+Y0b/E0JgNNd7S4t6NgdeAh4FVmhzjM8RgrCX+urX+9oW+9zWIu3mpjqmqbfDdbitXVrzPQrMTwj/M4DJXepofpYPBH5DPGtvalG+kgc3t6ujl3OhyJKyPW/T9RQh9O8rn71qeXeW/EWIjuYitXO+gxh9fL78z4c1f/poY0/3VbvPiDpw9YPttxRd9I3ARsCHgNdKOpPooZ5Qij4taTHgKuDnkp6g1ossbGp7/1rdF0v6Ri3/SUIwVzwLPOkYej9DhI/egHg4DfwJmFIr/7/Ad21f1XQOL0ja0/Zlkt5tu2PvSdJv6KDyAZ6VdCjwfuCtpWc3f71AGfLtC7yTGLrvZPum0uu+xvbqkiYQPUCIl89dZd/DGOopLy/pK7VzOaJ2mCskfRM4D/h3rcxN5ed/bFtS1QNdtOm67NvhHP8OTGCoVzj13IlecXWeHwa+CrzI0DUzMTqryrQcsdSYJOlHhFrjmKLaqc97/VnSG2zf3qGO6j/ZG3hLi//kH0VVU12L9xAP/VQUwQq/TLyU3wj8VtK+tm8tRV6StBcwDtippNWPcb+kTxJDf4hR6v21/DslvReYt4wGP0n0ggH+I2kR2y8QvfKqTUsS6pZqeyFgP+D1wEJVuksPFJgg6SfEyBbgfcT/CE0jL4eq5gLgAkmL1FRzFyvW6DizXK89yrU4uH65iNH7LcCmkjZ1o5rmP2W0Ul3vV1O7RxU69k8wrfpuZxpZiqFnfMmmvKWJXv1fibAzq0uSQ/q63PvVtavuzf8SL5N7iXvtNtsX04aiPTiMIZnzR0I992Qp0vW+6sTsrOoZT9yc7wU2tv1UGTLuArzV9s9KuUUJPeQ8xM22JKHbfrJW1yXECKJ+U77V9rYl/zTgDUQv3OUYt5UPwKLA7oSgA9iVUF0cpVhj4Pe2397lfFYAvgasZHt7xToEm9k+qVbmWGCFWjv3Inq+vy7b95brcTv3K0kAACAASURBVIPtqxWT2FvYPq1Wxx+Ak0r7GvSzkva2fXqHNtZVTkcQvVhgSN1Uyl3RYnfb3rLkfxYYQwjUrxNqp1/YPq7k96L3np94MFcrD0tzW+8jrl+n+Z9rCZ37bYTAeCMhjKqXxY7EaPJ22/cpdMZvcFEdSLqrnMf9hPCYOo9QO8YKdPhPFHrrE4E3ET3AB4D3uXFe5tfAAbafKNsbAyfaXr9srwN8hHhxn1GE1+62jyn5ryJGRVuW87oM+FStvkWALwLblHO4BDjS9ouSFrQ9VTDW2rQcsGL10pN0DjE6fC9xb7yP0FsfVPIXJHrjm5cqrgaOd8xLvNb2Xzr8Tx1Vc8TcQVvcqKbZGvgSsd7HpcCbgQ/YvrLk30o8H7dTe7HZ/kOtjr2Ao4mRuQhd/yG2zyr5fwGOtn1yeckcA4y1/SaF0cebiJfjlcDawLWEqud+2x8pdXQU7EX+XUWjzNrC9jtKfqv76v22H+x0reoXbbb8EEOlrYi32G8IXfUUotc3tlbuYGDlLnUtQ0wa3Vw+x1JTC9BiyNX0uRdYqFZ+YeDe2vZlhG6uUxsuJl4et5bt+QiBM80wtV0a0eMa08O1W4AQcm8gJvSm5/q3VCH1sf/WhM78W8DWTXl/IHpMbdUqRM/2XuCBsr0+cEEt/3eUYXSHNpxHCPJqe13gXGqqoVafWvnVy3E/UT7rEeFum4+zPPES2ZGi5qvlzVu+FwUW7+P6tfzfiN7mG5vSRs3If9Vjeyq1WKW+mZ+iQhrpD6FXX6xD/rLEiHdHYLmmvI5qylq5FYlR585Mq3pbrUX5t9Z+b0ZoGQBeTaiFdqdRfTSeGOWtUT5fIjqQLZ+HknZ7i7S+7qvqMzurel4ALpP0mO2dICakgIeJIW81jFwcuFTSFOAsoqf7eFNdU4CDOhzrq+3yynG3IN7gL5akBWmMKvoccHt5S9cnKz9ZK7Oc7bOLWgBH3KJXaGRRSWt6yIphTeKPrVgN+JGk0YQa5CrgKg+pBFCY4f2IGIYKWEPSh91hWNnutNtmhBrgMGpWD0RvZaoFkWMyeXybKhaxfb3UcIiXm8ocTrwcriz13aJGU7hDCVXMdTSqm+rXfC3X1DS275D0OuLadephVuqiXQkV43ml7OnEfNFxVWFJuxMvuCtLmeMkfc72uaXIA4pJ4rMI44FpUHtz2moi70pCAM1X2v6EpD/ZrlQgf5L0YDnGLz1k7dNRdehp1RudeKl8Py1pXWIi+FWSzra9e3k2pzmWa6OjbpSRycGEYD2gqKXWsn1hyV+X+A+WKdv/ICZx76zVUVlZXaSwsvqCpLrl27FFpXkprdWUdRXhI+V7paJZeMj2y7b/JmlpYjQ4Ve1Vq+saScvX6jm9WSYRo6kja9tHSdqjtn2ppD2Bs8v2e4BLmtRe9WtXHfs7rfKbmW0Ff413137/sTxQ1UNVCe2vFnXBHsAfJD1i+x2Svmf7U+0egOrGL6qHzzKt3q/Sgz9D6EnHl3q2Bq6X9P2Sfx5DaqB2PF+Gd5VObtNSb51PAVdKqvSzoxlalAbbh5V9Fwb2Jyb7vkdMPlV8B3i77Yml7KuBi4gRRz9MY2pW42Riomr3sr03MUH7rnLMdxHD31cRwrBSkSxRyvein3zJ9jNNL4f6f/gjQpA2DNmbuK2F3vk223t1OLc6+xE9t+dLO48hTAyPq5X5IrCRh9Qqo4DfM3SPrk30PA8ETpJ0IXCm7T/W6rio9nshYs7o77W0JR2WNh8izDgPU1gTAeCwnNqYsIL5YlFRnUmMtoaLE4uw+zKhn1+MUAWeX/J3HIZjnEK82N5UticRFjAXVm0ADrZ9BUztkP24Vh5ChbiepPWIl8hJwGmEqgViFLw3oRar6+G3rNVxPI0qwnWJSdslJX2U6IAdROj3bwE2Je6LLRWmsj8kVM5V53AVSU8DH6u9YFoK9lob9ifkQaWanZfoVC5Q2vv1Ftevd4Z7GDbcH0K/t1Rte2mKBUhTuRWI4fifGBqObli+39bqU9v3VsK8amNigmvDat+SP67Tp5RZmOidtDuPDUrbninff2HaIftuhJXKesQDdjFhplflf6mkXU3odHcneg71Om5o2lZz2jD8J62sSG6p/Z5I2JG3239NQji+QDwcf6RJhUI8sO8lHr4xhLD9YS2/rdVRrcxChGrwV+Xz6ZK2du0/meZT2/92GlV8CzGteq55e57mtKZ79zTglS7tngf4c1M7ViR6qRuVtGksYEr6cr0cY3b80MUihxbWOc1pdLeymkgX9SfRiXt9bXsd4kW+JiHoby/3wi0lf23CLJWSv0mLOjdtOpdnCRPhl4jR7n9L2rPAP0uZZQi/imlk1ox+5oQe/xtdhq4Ajkneqc5Gkj5GCMBRRO9gfxcrFds3lu8/KOL/V04c97o4gRRe9pCV0DS4NrHZCtUcZAjVylQHmVodN0l6G2HOpRZtAPiy7XMkLU70QL5F9GA2KfnvIm6Siwj1yjUuE3MacviYIOm3RE/CxMvkhk7tb3NOv7T97jbZ/5K0uUuvtQyv6xPJj9u+u0P1DzlGZIsSes9nW5T5BNGb/jdh9ncJYX5acbFimc7f0Dhkn1L7/SJhK/1dheXIKo4JzYOJkdS3mZZ67+8U4DpJlQ34rsQLqc7vFMYDle35HoSt/VTK/74HMZE8gaGRUjvGEKOliq8S5/9H2zcUFeB9tfqXIO6NPQid8q+JTkyV30oN80xpy1GuGUK0QzULryY+16LuqXholNcLHS1yCOulLzPUC34/jdZL0N3y7Q7CYueJDu14rWvqI9t3SVrb9v1lBPpiuY9QTI7foyGv6EVdHOfq2L5WjdZt5xOq2qtbPStldNc8qvizpEtsf0NtnD7dqOpsy5wg+OeRtLQbHY7q7V6VsGC4pV0FauFVqLBguaMU+Y2kA2kyTyR6mL3oLw9nWn30ms3lS5nRpf0bSMI1ixyGnITeCfzYoaecauni8PJdgrBU2JoYfj9he3OGzPwgLIGqoe1kYjTSL63aX/ER4LSi6xcx6f6BWv4EhSPNr2kUypU6rKve2zHH88XyaUWlrjm0vhuN5pxXMq1u/M+2DyjH6GiJZfs7pY7KUmVf2zc3lfmcpHcT/wmENc5UZ6Gie7+ZeBF/zkVtVEfSswzNOZjQn3++VmQnorf3VNl+ikY14a3Etf6q7WtbnMrFxL31i7K9J2E88RjhH7FTi32aqbd7IUK1c7ftxcs5HEmo604v5/E+YpTSD4cRk/arSvo5xSKnlv9B4iVY3UdXl7Q6exAjxf1sP6awsvpmLX8p4B5JN9BoqVWf77hT4WR4Zq3OuxSWSy8BjyhMzX8NjJf0FFDNIVys8DA+jZiPhJBR+5RzqzgJeAvw/fKCu4l4CVQOqgcRZuzX2n67IhTM/yPui28Qc3hPMZ3MtuacFZL2Ab5A9OYherBfc5NZosKkrW5f/LdaXkuvQmIoVZ/ka74Yb7b9qMKFfho85JZ/re1NVQt9oGlDOpxO9MZuYUjAu/6GLvrfSYRQ34DoRV9ve72Svy5xs7yN8OR8mLhZ2vXG+kJDMY5EjCq2L78brmet/BIl759N6ae0qN4e8jpchBAcexLnOY3eu9u8i6SFSo++ftyGtOr/KL2nVV10403/y7rEUL5+79RfxjOEpCWar8901NExzIYizs4XGAqhAQx1TNQ5XMjtbvLa7rFNCwKX2N6ibN9a3ae1MtOkdanzZ4Rq719ET/46tzDXLSNi235uOtp9IEMdvqnJLuaepczChC9E9cL/E6H3f5EwTHiuVvZthD7/d7b/U9K2J0zCVy7FJhEWac0jwXkJ4f52ojP1L9trl7wbbG+k8NrexGEWWzmHvYN4mW9Bk4FCfcTbidm+x2/7NLVxOIKpapbv0BSrh3A0qZjfNVtw23+RNL+HQjbU/2gTPYkf2v5X+XN+2qV32MlBpmIssI47v2l3J9QB37L9tMKu/HO1/KMZ0u/f0EJVVAndVqOT5p5RK05l6EW4etmueqFTJ7/UFMNGQxYFR5TvTg5aVW/+bOBsxYThsYTqqj5JfQ4xSfYTauESavyZeGl0SpuvXMPdaTFyUFh3bEEI/t8SL7o/Er21jkj6o+3Na731qVll+yjb3wC+puLIVqd5SC5pZaYV3JVDYLdR78+Il+QdtJ7onlfSxravL/tvxNC1bram6pVFCDVExfOS3seQ89VeTOtI2Y2qF7w10Um6WdJVVS9YEYDwNBqtesbZnirIFUYTxwGvI1Sv8wLP2a6csD5KjEq+Qbzsv0E8m5tVdTj8X75NkyqweomrMRZUZTW2qKRXbL/isKDraEwh6TLCYu8a4pmeaiBQaDequJgwH1+TRgfH6r7rNFKfymwv+CF0bMBdbbKPIvRfDbF6msrcqPZehRAC7p+EQIUYKp5KOMm8Ium/kpZ0U8CzGt300RAP5Qp08K4rAvG82vaj9fK2d9TQXMVaklrNE1xY+93KQqQt9Zdb6VFu2abo+QzFsGnl/LMK8fBV6o+rgYNsP1Ir003v3XLeReEwtTKwsBo9c5cghFGdI+igGycsKdYjJhP3lbQ8Q/dIR4p6jUrV0aKdlfpkQqv8prLHUNQJ1EaDhA4YQgBdo3CigjLqrVUx2bUgYi34EHCywsNdxL2+n0Ln3JN1SJO6c15iTq3uzf1e4gV+bCn3p5LWM7avUMTBqfeCX1/qhLDkarbqqZyYKn5AjCTPIQT6PjQGaNuEsDj7M2EKXqmU6ufaHISw4i5ipFo3B66uiYDFFM6gLxE9/uVL/hPEM3O0h+YrbyOMSNYlnqWnJV1TXjrYrmJSHa5wmKyPKo6TdILtj7a/ml3wbDCbPyMfeovVsyBh2lWZXX4aWLCWf1eLeu+q/T4f+BvRI5kaP6bPdl5B6OQuobirU3NI6rGOtxFv/T8QQuEBao4jbfZpsBDp41idYvV0jGFD2O/vSzw08xF62vG1/AcJK5u9iMmwVnUcTozCVqTRwWocQ7GPLq99zgf+t6mOZbu0s4p3ciPx4hBwzzDfn7t1SyMc1RbsUs86wMfLZ52mvK2IkdFexCTvu2gRB4oQHh0dDTscf/XaZ2VgvuG8TuUYlxFert8t59DsDNeLVU8lD+qxdepWQgsQOv9bCAufPVvUeQ8x+nsV4Qy2bPO9xLQWN2+ljC4IPfwKtbIrAIcAl7Y41uJEx/EhItDbsF7Tdp85osffhSpWz9W0iNVTVDW3OnRn7ZwbblLE/Li27LMJjT21jnb65Y3cajhf7zEf3tvpdOQ7wDaedq5iww77NFuI9MqxHfK6xbAZZbuu5/+ppE/B1P/jZDfG/mnFuPJdV3XZEVnzVIVzjmmcA3gDjVEYry060lOAi12etNIOEXb+SxG24DcSD+01XdrVL4cyND/VLu1+wvJkmtFThTuPevclTArnp9E2vQrh2+Bwpwjr0eBw1wPz0Rga+t2S6qGhZ0TFWNGxF0xvVj0vlFHxLYp4XI/SGH/pBqKTsBFh+vpDRRyt3WplnnHnODotLW5sbyVpkksojQpHiPejJe1bq+PjhFprQ6IjdDIhw0aE2X5ytxtlovBForf2fqLn9nM3xto/n4hqOM0EZcm/mzCzrPJXI3phLxM382aECdcrpfy8RA/thbJdF7wLEfrvl23/33CdZzlOw8Rkc1oRZq8QAqziMeBQdwkQV6vvVEItUz3QSwPftv3B2nB/PjrEsCn6y1MYMnHci7CIqeLLX297Y/pE0ooO9RcKE8qnCGuIdiGTq4mwDxIP+tnEfM1fSv7UiU2FN/QStqc6Rs0IZYJvB0KFdVYtawmix143t/wloXK6jPZeyJ2Oda/tlous1Oq/g6GYN3sD69luGfO9TR3dQkPXTX+nqhh7PYemYy1OjBI/S/ScFyzpSxNWPfV4QId7yNoJhSHG40TP/tPEKOd4Dzk0jrXdoH5TUwwrSUcTvfeWQQjLc1BZ3KyvYnFj+12SLiV8VE518dYtKsQPEKFLqlg7ny3tv9H29M6zTDdzrOBvM7lWzXD/lzAx/Kbt44ve8H+IeD/1kAqV525Lq50aZwHvcJnNLyOMS22/qd0OvQg3SSe6mBb2gsK1/780zlXMW+9VqZ+Y3K2P0daCpNt18pCV0+qEjn8z4r/5M/DJ6sUr6btE7/QsGv+Pm5rrbGrHhbZ3LL/7Os8y9/MzYkLtVmLo/RHgB7b79nPo4XjrEXF+GoLdUcJzNwmrcbTAXfxHavufQtzrLUcEkm5xCfjWKa3LMSoroP8jrE+Oa3Wv1MrPQ8yttH1GWuzT3Au+mrBau7yp3JLAf93a/4PS41+buPfudbG26aMdV7RItocsylpa3DgWf1qauLfqOv7HCdXuMe7R6mZmM8eqetx9cm1ZQuAcT3jBdqrroU75CjPB52rlnysjjSq/Pss/D3HjNodybcWPeihT56OE63/Vi7qaOL86N0raaAaEWVsLkppgP9323vWdFOaqe9fKdYoDUwmcurqnwXKoFZXQL3QNmVzugfcTE3yPEbrUC8rxzyF6c++T9BDxApom+ub04oifdKvC+ev55tFiU9meBHwHNiVUGw/QOopoN4e7XqhCQ+9D69DQzUyPinEhQp3ZshessEY6mdCLo1jZ64Mujpol7Z2ENdh0x6pyF/8OOtjxOxxMTyHmua51o+nndjTa8s8y5tgefy/UVQMzWM+fCFVRNdTbkOgpbla2H2Bolv9lYtL1CDfGY6nqWoJ4KFv2VoahrfcQK39NlzBTD34TarILL8LsdtvrlO1RRKyR0TSaJ/aj723Xvp7UTaXsXwh98Mm2JzXV83mGHHQa6NYR6LO919JmtKhhCnDWbiRWe1GvT6h56g534/pRa6l7aOhms9a+VIw9tuE24EDbV5ftzQk1Tv0/vwfY0U2xqlzs4/s41juZdu2Baeal1GTHr1gX4UDCpHx9Qm16finbdlW7kWZuF/zNN2MD7tGdvPQ0ziTMIkXM0u9R72n0WEfVWxHwNE29lQ77thQMFU03fkch0GNb12Go9325hxZqOZR4KSxMxNmBOJf/EB6rh5Zyf6boL2nUv/+y5C9PeCG2XZugQ9t6UjeVsh0dm0aCTmqWqmMyHP9Zj21p6XA3p9BGDdncCbnB9ka1bRFOkBvRI5J+SJgGv52wlnpPqWO/Hva9nbiXn1PMG51LROc8tpNqbKSZqwV/hdq4k7sPj1fFwiDVBFqD/bzaLIxcYfu8XnorHY5dCYYDy3fdqsG2D+n1PIYDSV+vhHyb/I76Y0kXE5O/X7S9nqT5CJO7vj1Iu7TzXlo4Ng23QO3Sho6jxRFqQ9cw2h32bTcqmWZC302Lh7dKm872V4J9H6LTcUZpyx6E0cXBtWdwa+JFX49V9TfbH+vjeNVazNX3YoRV2Ft62PdO26+vbS9GCP+7gC37mVeZmcyxOv4+2dmNruMnKFbi6UnwS9qNGMrdIelLRJydozw0Gbkf4URSTUK9nZhfmMyQWd0rldAHsP1HST3N5teG7Fs39Rg+r1iAfEQFP+E8tgNxTVp5il4oaQc3uajX6GVtguGgm2PTSPAp4BxJDaNF6DgibQ5jPaN0DKPdhWodi58SNvaP1DMVSzIuAixXJjYrA4slGApZMKM0B9M7rPa7un7DGauqmv94QbFk6ZP0HnfocUnru8QOKz3/HYn/YFg7NjPCoAj+GXUnr6Jmbk44yzRHzZyfMNGrTA1XJMwG66EL/qBY37XeW7my6s24i0VLQZLebPtPZeNNNNoojxTHE7bjxym8SU+xfa8ag419QdJ/GFrAoy7IelmbYDg4TOGx3Wwm2W3thGHD4TG8Ni1Gi25jmDATeLUbI61+VWGR0pXaHNlihJdsw4JHkg4iXm4rEaq9ypv1WRrXLZhuephsxV3ChPTJhWXy9puEubAJlU8v7ENTGAzHRPU+5fmfLRgUVc9owiHpzQy5k3/KPa5PqSFzxq8Tk5i/UGOQrLttv65Wfh7gzqa0ViZiFXb78Aj1dmxI9ByqSbqniHmCXl4aw05RIexFhKt4mHCE+plbxBBq2m8DQiisS/RERwHv6Weyscf2/Yww67uTmmPTcEwy99GGalWp1W3vr6ZVpUaoDdcQkUHrVj3fmh51k4YWPHo34dBV2aV/BfieI5bNl4mYSUcO573Zy9yQui8K3+8xFyTWZJgZHZNZxkD0+IuA32UGqphU3tZbA8eUm6He075MjTHZ9yScOOpt6Npr6UaZCF6vCFxm5c1Yeux7E/MMNxMxTzYnPG63KDrXqUHvbP+6tvurCZf4VQkBsgkz517cyB0cm0aIU4iecCVkm1eVGgnqYbQhOgwtfQd64AnCYudJGs0132P7iDIqbrWWxHDwU8rcUNn+CzH6qBsFnE6EXNiW2qLwvVQuaUvbl7eas1ME2ptC+CbMDLXkiDIoPf4ZMi8svbbtiN7+fUWV8wbbl9bK/C/hfAKxDu6vm+o4iLhpnyV6xhsAh9Tr6KEdDVExa+fRLfzBsKKwTV+LeMhOcbikV3kTCEe519C4OMlfbR9YylSTZpsTwey+BXzF9nAKia6OTSOBpAm2xzaNEPsKVzwMbajWaV2sfD9HCbLnDutYNNXRvODR2W6MkttxVDxM51E5TtWvZYMhQa0d1T02P9Hx2LSH+g+3fbgaw0/Uwx4vCyxse+vhOqdZxUD0+An38quJXnjfb2uXqJmSXqWhmPX3aFrv4eom2V9Sg/cwoZI5VtK2xA20NyE4exb8dImKOYKcSAyl3wyMlfRH4ATbLxYhdw+x9GKlwz+VULdUdFxwZhjp5tg0EnRbVWokGFs+FzBk1XYb8BFJ5zjCR3ej24JH3UbFw0Evc0MtF4Xvsf5ny0vyDhqfZwM4FubpanI8R+ARigY3Kz+0WCO2z/13JsL5Pk84Z71C6PC77bcsMZkHQ+sAH0uJIkkP68Y21dcxKuYIXs+zicmut5fPj4nJvir/Qmpr6BLmdb9pyv8R4Xy1FOHJOk3kxWFo5+qtPiN8rbYmzCcnE+qwB4EtRrgNVwGL1bYXK21amBaRaafzGIsQVkJjyvaKREDB4TyPXtat/hCxtvFby/31BPDhHus/rHx+UZ73bxEWRX8h5q5G7D+b2Z9BUfUcRUTPa2de2G3/Wwm9ZUPMf/fm0FE56ZxCmLetQQTkmhe40nanyJrNdZ0IHOcOYQpGAkl3uXjptkpTRH/ciFD5mFhycgJDvbM96aI6m5sovdRNiR7ktW6xqtRMPv49xPV9qWxXL9q1h1sdM7NR+Hy0Xbda0hq2H+iW1uUYVwHvdPGuVwSNu8j2WzvvOecwKKqegwjzwn8TQ8F+7aRfsv2kpHkkzeNYMOJ7vezoIXO4/QgX7vmJYfdyxGRVP2wOfGAWqy6gexjrjv4R7rLgzNyAYnHuezTkfFSd32qSVgWmeOQcyX5OLBp/ftneCfiFYiGWWTb/0S+KZRN/7rIQuqSlJe3lUKVW/JJpV2Y7l86hy5tZnvBGr/hPSZtrGAjBb3txRbCxMdRMvPqgivl/FS1i/vfIB5k2hvc19GfrvH2fx5xZbEgESWsIY63i3TkLXkSzIwcDBzCt81HFsmWSd+82+cOG7SMV3tLVSlMf8VBo4vfN7OMPI/vb/v+qDUdAtP2B4xW+Eq8HlmyyylmC/p/504DrixEDwK7030mbrRkUVU/bhRN63H9RwptvHuJBWZLoeTzZRxvaxvDuYd9Wa31OxSMc6lXt4+WcS8Q1qSbHpu7C8HqizhVIutT2NrO6HXMK5Rl6o4vQUgQHvM0RDnkXQkDvTExiVzwLnGm7eQ3sbsfagEYrvZtn+ARmIwZF8E+30C37Hwyc5aYIj322oW0M7x72vdCx3m49CmiFHatSJbMhxaHoY9R8GoAf2n5xljZsDkTSN4kJ+soD9sPAw7Y/Uyuzme3hXkVtrmMgVD1EIKcXJSFpwaJ77cexZ3HgUkkN7up9tqFtDO9ueCgO/Z8Ia4yrbd/T5/GTWcNpNIYveC9hxrtb2z2SdnyeEPbVIuPjmTaUws1lLmBYPHfnVgalx/8rIrbMpwjrnKeA+V2Wjeujnpbu6tPRnoYY3n3s93Zi+PkWwvv1JuIl0Gl93GQW0s0CKhleFLGj7iFesFM9d20f1HHHAWMgBH+d6RW6Zd8ViJ7ansDis2ISs+g1NyLs5z9CLIPX1yITycihiBf0gyYLqANt7zNrWzbnoYhz9HVgHRp782vWyky35+4gMSiqnqnY/kO/+7RwV9/fsyAMgGIR80UJa6CriVg0T4x0O5LuaCh+/fwMWUCZ0FGnmm76OIVwsPou0fHZl2m9g2fEc3dgGDjBP510c1cfKW4jTCnXJZyhnpZ0je1+109NZj719YGXpmYhQqy+lvTPwrYvk6TiA3G4pBtp9Bs5UbEuwJcI657F6LLm9iAycKqeGUHSq2gcYv6tQ/GZ2Y7FgQ8Qq0utYHvBznskswpFcL4PEQ5rIkwOf2x7WGLVDxKKJT03J8yGLycinR5tey0NBaJr2KV82/Z3RqiZcwTZ4+8BSTsB3yEWm3iCGK7fTVgOjGQ7Pk70HDckYr6cTKh8ktmX/YBNbT8PIOkY+nfcG2gknV4c3X5NxAT6JBHVdUuGwktXi9qsRcyBVbb8OxGhQ5IaKfh74yjC6ashVs8saMdCxAvoRseqPsnsj2iMCPsKjX4YSXc2VCyB+D4iIOALwGfqBWx/FabG2dmgFmfncOCiEW3tHEAK/t6Y7lg9w4ntb430MZMZ5hQiTk7d/X/uCO07cvyQWD5zTRqXd6y+6w6Mc32cneEgdfw9IOn3xAN7NBFq+QnCouZNs7RhyRxBcf/fvGxePbe5/48Ukk6w/dEuZb5IWODVX7Rn2f76zG7fnEQK/h5QrMD1ItHDeD8R+OnnIx0jJ0mS7sztcXaGgxT8HdC0K2zBkH62eYWtJEmSOYIU/DNAWWDjz571C3onSZL0TAr+GaRaYWtW2xNA4QAAADFJREFUtyNJkqRXUvAnSZIMGM1xLpIkSZK5nBT8SZIkA0YK/iRJkgEjBX+SJMmA8f8DzwydAtT6y+QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# frequency of the top 40 tags \n",
    "temp = pd.DataFrame({'Tags': tags})\n",
    "temp['Tags'].value_counts()[:40].plot(kind='bar')\n",
    "plt.title('Distribution of tags');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YCpPSbAHxwJ9",
    "outputId": "a0020449-a98e-413c-eb0e-e9900c065a0f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1645652841281096"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(temp['Tags'].value_counts()[:10].tolist())/sum(temp['Tags'].value_counts().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4LrKWIly4X1q",
    "outputId": "6e612f6e-2354-4e85-d64f-d7e9a3829177"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['c#', 'java', 'android', 'php', 'javascript', 'jquery', 'asp.net',\n",
       "       'sql', 'windows', 'ruby'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_tags = temp['Tags'].value_counts().keys()[0:10]\n",
    "top_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4X2JtaeTdBw"
   },
   "source": [
    "# Data Loading and Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xShugfq1vjNJ"
   },
   "outputs": [],
   "source": [
    "def seperate_tags(tags):\n",
    "  # takes a dataframe column of stringed tags and return a set of unique tags\n",
    "  tags = tags.astype(str).apply(lambda x:re.sub(\"-\",\" \",x).split())\n",
    "  tags = tags.transform(lambda x: set(x))\n",
    "  return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Wb7mnezLnR9p"
   },
   "outputs": [],
   "source": [
    "def pre_process(text):\n",
    "  # do all required pre-processing\n",
    "  text = BeautifulSoup(text).get_text()\n",
    "  text = text.lower()\n",
    "  text = re.sub(\"[^a-z]\", \" \", text)\n",
    "  tokens = text.split()\n",
    "  return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "vqmPoTmUn3tq"
   },
   "outputs": [],
   "source": [
    "def fit_transform_target(y):\n",
    "  # encodes a multilabel target y and returns the transformed onehotencoded vector\n",
    "  mlb = MultiLabelBinarizer()\n",
    "  return mlb.fit_transform(y), mlb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "tYvxos-2lUNO"
   },
   "outputs": [],
   "source": [
    "def preproces_df(df, top_tags):\n",
    "  # loads and preprocesses the data to limit the required RAM\n",
    "  question = []\n",
    "  tags = []\n",
    "  unqiue_tags = set() #{}\n",
    "  lst_top_tags = list(top_tags)\n",
    "  df['Tags'] = seperate_tags(df['Tags'])\n",
    "  for i in range(len(df['Tags'])):\n",
    "    temp=[]\n",
    "    for tag in df['Tags'][i]:\n",
    "        if tag in lst_top_tags:\n",
    "            temp.append(tag)\n",
    "            unqiue_tags.add(tag)\n",
    "    \n",
    "    \n",
    "    if(len(temp)>0):\n",
    "      question.append(pre_process(df['Body'][i]))\n",
    "      tags.append(temp)\n",
    "  \n",
    "  encoded_tags, target_encoder = fit_transform_target(tags)\n",
    "\n",
    "  return question, encoded_tags, target_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ZIEGTqsErY3z"
   },
   "outputs": [],
   "source": [
    "# read the dataframe directly into the preprosseing function to save memory\n",
    "questions, encoded_tags, target_encoder = preproces_df(pd.read_csv('/content/drive/MyDrive/Final_Project_DL/sample_train.csv',encoding='latin-1'), top_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pKgBA0rb7vd-",
    "outputId": "c5d255d9-7f56-4d6b-b64f-ebca80e177af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46072, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_tags.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "0znrk_qYhONl"
   },
   "outputs": [],
   "source": [
    "# splits into train, test and validation\n",
    "x_train, x_test, y_train, y_test = train_test_split(questions, encoded_tags, test_size=0.1, random_state=1,shuffle=True)\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, test_size=0.2, random_state=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dsyDb8GUiyZU",
    "outputId": "263ddacc-52cd-4748-e20b-78f90038be45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33171, 8293, 4608)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train) ,len(x_validation), len(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k1K5ZvOsT0Wd"
   },
   "source": [
    "# BERT preperation with Dataset, Dataloader and LightningDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "x34OWrAO0Hu-"
   },
   "outputs": [],
   "source": [
    "# the dataset class\n",
    "class StackExchangeDataset(Dataset):\n",
    "    def __init__(self, questions, encoded_tags, tokenizer, max_len):\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "        self.questions = questions\n",
    "        self.tags = encoded_tags\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        question = self.questions[idx] \n",
    "        \n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            question,\n",
    "            None,\n",
    "            # adds the [CLS] start-of-sentence token \n",
    "            # and [SEP] separates the sentence token\n",
    "            # same format as used in pretraining BERT\n",
    "            add_special_tokens=True,\n",
    "            max_length= self.max_len,\n",
    "            padding = 'max_length',\n",
    "            return_token_type_ids= False,\n",
    "            # return the attention mask for our model\n",
    "            return_attention_mask= True,\n",
    "            # truncate data beyond max length (300)\n",
    "            truncation=True,\n",
    "            # returns a pytorch tensor\n",
    "            return_tensors = 'pt'\n",
    "          )\n",
    "        input_ids = inputs['input_ids'].flatten()\n",
    "        attn_mask = inputs['attention_mask'].flatten()\n",
    "\n",
    "        tag = self.tags[idx]\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids ,\n",
    "            'attention_mask': attn_mask,\n",
    "            'label': torch.tensor(tag, dtype=torch.float)\n",
    "            \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "rvJk2UMI0Zgf"
   },
   "outputs": [],
   "source": [
    "# borrowed from https://medium.com/analytics-vidhya/multi-label-text-classification-using-transformers-bert-93460838e62b\n",
    "class StackExchangeModule (pl.LightningDataModule):  \n",
    "    def __init__(self, x_train, y_train, x_validation, y_validation, x_test, y_test, tokenizer, batch_size=16, max_token_len=200):\n",
    "        super().__init__()\n",
    "        self.tr_text = x_train\n",
    "        self.tr_label = y_train\n",
    "        self.val_text = x_validation\n",
    "        self.val_label = y_validation\n",
    "        self.test_text = x_test\n",
    "        self.test_label = y_test\n",
    "        self.tokenizer = tokenizer\n",
    "        self.batch_size = batch_size\n",
    "        self.max_token_len = max_token_len\n",
    "\n",
    "    def setup(self):\n",
    "        self.train_dataset = StackExchangeDataset(questions=self.tr_text, encoded_tags=self.tr_label, tokenizer=self.tokenizer,max_len = self.max_token_len)\n",
    "        self.val_dataset = StackExchangeDataset(questions=self.val_text, encoded_tags=self.val_label, tokenizer=self.tokenizer,max_len = self.max_token_len)\n",
    "        self.test_dataset = StackExchangeDataset(questions=self.test_text, encoded_tags=self.test_label, tokenizer=self.tokenizer,max_len = self.max_token_len)     \n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset,batch_size = self.batch_size,shuffle = True , num_workers=2)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset,batch_size= 16)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset,batch_size= 16)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "2ca9df8de3da4eb68a1ebaf769f98da5",
      "5e4bb0e682a64691bc929674c7a50d26",
      "55a31116efbe4f8f8c9729d02daf7661",
      "2dff1feabc484a7997367f81fab26b1c",
      "5ffa5fbf9b714051b29b1922799da293",
      "e3cecacb4b9344e8bdc48239a42397e7",
      "b77e58181369403a90e567dd7c8089b7",
      "6c2666bb5d154b5d87cdc93f5d0f76f1",
      "038d50422bd046519f973a34585d9fb1",
      "23a51c9074514f5baed9840f88fde66a",
      "2451f19bb20a43eb8a1b6d9e387b62ff",
      "6b50810b67f748d5a591fc0fe91c9288",
      "88a1666d808b418f96a2de21048d78c5",
      "fa1e0c836dae49e3b1144f8cd3b3bfef",
      "f648699b37c4457c9dfbd156eb49d05a",
      "9fcb2fced1f14fbeb89da048942599d4",
      "9a96d54b8ff7466588beb73370b14015",
      "ef47b6a53a0849b1ae25c3f1fabbf3b7",
      "1dc20a5ad0ac4cca9551d4636c7179f3",
      "1b5d8f30a5394ab7a45140707b99f8e2",
      "75a96f5b261b4681a04b4fc18f1709db",
      "2b68cc5721f6491aaaaa995e3db24261",
      "18a7776ec5a64d729e271ddc50e32c4c",
      "45cdb8cf59864ccfa4dba14c486f9bea",
      "b31a637c0fe44077b9633c725a31e2e2",
      "a5ac75e7eeb74991bd5dcc3bc505c6f1",
      "bde6e91529474a2c8a7c13e602d7d99b",
      "d3370373c72f49d4b5621a3e4dd17a97",
      "b9fbf8b11d074192aa2047227d5365b7",
      "5438ac3023d64c59bbdd4931206e1796",
      "c5431bdfd64845bca34fa25f1b7d3477",
      "23427faabce64f289d8a96c110a8f9d6",
      "aec9a4d7d24a488d90a86d5c86952e3b",
      "b5db616c20db48d0bce492de2bbfa1be",
      "9b7ad1d148f147509f781bc5f8985963",
      "42b03ec1eea64e51a261b4b7ce3bf1e0",
      "ace002f962ba4e6d854095f25a3167b0",
      "620890c9a465490e89af0c7a54c827b6",
      "dc8493481a30459bbac2977662912c59",
      "5d81efca9fe046b792e965021bc0df26",
      "143f5279bbf64644905f25bdaa24f9bc",
      "8ab2a66f084b4890a7e27cce2220bad5",
      "7dddaafc05b8472cb4606d93b947e27f",
      "8ee617952be1489d957fdbb49a191d42"
     ]
    },
    "id": "tDZ_BiaO0bps",
    "outputId": "b292a816-45b5-4e44-be2d-e8aacf871675"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ca9df8de3da4eb68a1ebaf769f98da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b50810b67f748d5a591fc0fe91c9288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a7776ec5a64d729e271ddc50e32c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5db616c20db48d0bce492de2bbfa1be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize the BERT tokenizer for our selected bert-base-cased model\n",
    "BERT_model = \"bert-base-cased\" \n",
    "Bert_tokenizer = BertTokenizer.from_pretrained(BERT_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WQoPwA3JjHa7",
    "outputId": "c25cab6d-a24a-4645-f3e4-598799e8608e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Question having word count > 300: is  7900\n"
     ]
    }
   ],
   "source": [
    "max_word_cnt = 300\n",
    "quest_cnt = 0\n",
    "\n",
    "for question in questions:\n",
    "\n",
    "    #  to use Bert_tokenizer we need to covert the appropriate format \n",
    "    #  Bert_tokenizer adds tokens [CLS] and [SEP] and [PAD] to obtain the corresponding embedding\n",
    "    input_ids = Bert_tokenizer.encode(question, add_special_tokens=True)\n",
    "\n",
    "    # updates maximum sentence length.\n",
    "    if len(input_ids) > max_word_cnt:\n",
    "        quest_cnt +=1\n",
    "\n",
    "print(f'# Question having word count > {max_word_cnt}: is  {quest_cnt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "rFoP68fZj-Zz"
   },
   "outputs": [],
   "source": [
    "max_len = 300\n",
    "batch_size = 32\n",
    "n_epochs = 5\n",
    "\n",
    "StackExchange_module = StackExchangeModule(x_train, y_train, x_validation, y_validation, x_test, y_test, Bert_tokenizer, batch_size, max_len)\n",
    "StackExchange_module.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zB6jp9FCX10h"
   },
   "source": [
    "# BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "VCfEWt7g17eJ"
   },
   "outputs": [],
   "source": [
    "# the BERT  classifier model \n",
    "class BERTClassifier(pl.LightningModule):\n",
    "    def __init__(self, n_classes=10, steps_per_epoch=None, n_epochs=3, lr=2e-5 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained(BERT_model, return_dict=True)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size,n_classes)\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        self.n_epochs = n_epochs\n",
    "        self.lr = lr\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "    def forward(self,input_ids, attn_mask):\n",
    "        output = self.bert(input_ids = input_ids ,attention_mask = attn_mask)\n",
    "        output = self.classifier(output.pooler_output)\n",
    "                \n",
    "        return output\n",
    "    \n",
    "    \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['label']\n",
    "        \n",
    "        outputs = self(input_ids,attention_mask)\n",
    "        loss = self.criterion(outputs,labels)\n",
    "        self.log('train_loss',loss , prog_bar=True,logger=True)\n",
    "        \n",
    "        return {\"loss\" :loss, \"predictions\":outputs, \"labels\": labels }\n",
    "\n",
    "\n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['label']\n",
    "        \n",
    "        outputs = self(input_ids,attention_mask)\n",
    "        loss = self.criterion(outputs,labels)\n",
    "        self.log('val_loss',loss , prog_bar=True,logger=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def test_step(self,batch,batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['label']\n",
    "        \n",
    "        outputs = self(input_ids,attention_mask)\n",
    "        loss = self.criterion(outputs,labels)\n",
    "        self.log('test_loss',loss , prog_bar=True,logger=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters() , lr=self.lr)\n",
    "        warmup_steps = self.steps_per_epoch//3\n",
    "        total_steps = self.steps_per_epoch * self.n_epochs - warmup_steps\n",
    "\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer,warmup_steps,total_steps)\n",
    "\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120,
     "referenced_widgets": [
      "fe76a6772afd48909e8c2a3fa13c89ca",
      "d9b35365876b4f59a74806c84a751e9d",
      "30fd66e09fc342bc87bdefa0d22023ff",
      "85349bebadf943ec91e88ab4f0141c81",
      "d82f990e653d4e53ad81afc73977c2fe",
      "126639cbf887416faedbadf3398bdb50",
      "466c10a3ea714ba5b3b23426f240e2b5",
      "1b6f7500a83b40829284f138982ae35c",
      "6fe29c7de1f7433b8690479843bae4e5",
      "566be7cc6ae74146bebfd673e77c7f79",
      "ebd4b28c367546eb82372afbc072c825"
     ]
    },
    "id": "4GPm_0ot1_j2",
    "outputId": "4e3931b7-398e-459d-83fc-3ca659cfb38e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe76a6772afd48909e8c2a3fa13c89ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# set up BERTClassifier model\n",
    "steps_per_epoch = len(x_train)//batch_size\n",
    "model = BERTClassifier(n_classes=10, steps_per_epoch=steps_per_epoch,n_epochs=n_epochs,lr=2e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424,
     "referenced_widgets": [
      "9805cae795a44bb39af672160641b044",
      "458c462a30c7488484c49ed0533ee5c9",
      "9233e38da9c74c86b95ad85eebd101f4",
      "05c47cc07c4c4746be34e005f9a8316a",
      "13930a48934d450fb247b567ea30ef81",
      "0374170f03364a70949d5364525401de",
      "c46279f125474889934ec33398425c16",
      "2f821bdc0b1240b7ac56dd6176a3312d",
      "c2d2a1f89a66402e9625de855d76b812",
      "0d7fb007fd7b4085a98328600d216c71",
      "b8a2724be1104a199619324d402e13d7",
      "ae8a44cd17964ce387080a76379a6a7f",
      "0d50416890d94f77b18f85fb6028d8c0",
      "0e06bc01f1d843e998a2240111fbf7f5",
      "b0de2ea5187e4b7aaca370421b87779d",
      "6115810963da4ed4917ab586fa8d2a5d",
      "2789a90d182146faa1f9bff153e020d6",
      "60667d9415de4dc5b471a2db7e0c395d",
      "e5431b2cb0bd45ab8f0cd9d7a31adc5c",
      "1d32b1cf02e54b3f9bd590ec9202a84c",
      "c8aef14d223b4a218c73fa21b689b7df",
      "f1b48f446a674a20a8e0edc3c21e7124",
      "15a81cd980a2425ca281763f8202e348",
      "a779cc040b704d13aa5c88862058de07"
     ]
    },
    "id": "NV9iLkKwrvMq",
    "outputId": "b6a2692b-0141-4fb0-ec76-826ad53df064"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/datamodule.py:424: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.\n",
      "  f\"DataModule.{name} has already been called, so it will not be called again. \"\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/datamodule.py:424: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  f\"DataModule.{name} has already been called, so it will not be called again. \"\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type              | Params\n",
      "-------------------------------------------------\n",
      "0 | bert       | BertModel         | 108 M \n",
      "1 | classifier | Linear            | 7.7 K \n",
      "2 | criterion  | BCEWithLogitsLoss | 0     \n",
      "-------------------------------------------------\n",
      "108 M     Trainable params\n",
      "0         Non-trainable params\n",
      "108 M     Total params\n",
      "433.272   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9805cae795a44bb39af672160641b044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d2a1f89a66402e9625de855d76b812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2789a90d182146faa1f9bff153e020d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/datamodule.py:424: LightningDeprecationWarning: DataModule.teardown has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.teardown.\n",
      "  f\"DataModule.{name} has already been called, so it will not be called again. \"\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs = n_epochs , gpus = 1,progress_bar_refresh_rate = 30)\n",
    "trainer.fit(model, QTdata_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324,
     "referenced_widgets": [
      "e4c165c0ca0d48a19374c7728fabd61a",
      "e9a702be97cf4f248bbd3e5d2a6b5e44",
      "1fdc98201f184946a32c7429ecc8579e",
      "4cda09783f7b4f23a7f01367fe90cf50",
      "34b58c9449584c7db22c9a4d67f9ed7c",
      "320076a744994fae9842eada281aef56",
      "b29cae1d62d643c2a4c61bc0b7574c6e",
      "60c9b2013ac340f1853d55a3205112df"
     ]
    },
    "id": "7EUyeEGyr4oi",
    "outputId": "89af9cbd-1149-409f-90b4-518b8d854e23"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/datamodule.py:424: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.\n",
      "  f\"DataModule.{name} has already been called, so it will not be called again. \"\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/datamodule.py:424: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  f\"DataModule.{name} has already been called, so it will not be called again. \"\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/data_loading.py:106: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4c165c0ca0d48a19374c7728fabd61a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': 0.20340345799922943}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/datamodule.py:424: LightningDeprecationWarning: DataModule.teardown has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.teardown.\n",
      "  f\"DataModule.{name} has already been called, so it will not be called again. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.20340345799922943}]"
      ]
     },
     "execution_count": 142,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model,datamodule=QTdata_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-MBKm_vby5_"
   },
   "source": [
    "# Test Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-14T05:44:46.681811Z",
     "start_time": "2021-08-14T05:44:46.677419Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# perform the same tokenization as previously on the test set\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "\n",
    "for quest in x_test:\n",
    "    encoded_quest =  Bert_tokenizer.encode_plus(\n",
    "                    quest,\n",
    "                    None,\n",
    "                    add_special_tokens=True,\n",
    "                    max_length= max_len,\n",
    "                    padding = 'max_length',\n",
    "                    return_token_type_ids= False,\n",
    "                    return_attention_mask= True,\n",
    "                    truncation=True,\n",
    "                    return_tensors = 'pt'      \n",
    "    )\n",
    "        \n",
    "    input_ids.append(encoded_quest['input_ids'])\n",
    "    attention_masks.append(encoded_quest['attention_mask'])\n",
    "    \n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(y_test)\n",
    "\n",
    "# load the data into the DataLoader.\n",
    "pred_data = TensorDataset(input_ids, attention_masks, labels)\n",
    "pred_sampler = SequentialSampler(pred_data)\n",
    "pred_dataloader = DataLoader(pred_data, sampler=pred_sampler, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-14T05:45:02.030914Z",
     "start_time": "2021-08-14T05:45:02.027923Z"
    }
   },
   "outputs": [],
   "source": [
    "# use BERT model to predict on test set\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "pred_outs, true_labels = [], []\n",
    "\n",
    "for batch in pred_dataloader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_attn_mask, b_labels = batch\n",
    " \n",
    "    with torch.no_grad():\n",
    "        pred_out = model(b_input_ids,b_attn_mask)\n",
    "        pred_out = torch.sigmoid(pred_out)\n",
    "        pred_out = pred_out.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    pred_outs.append(pred_out)\n",
    "    true_labels.append(label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-14T05:45:42.048113Z",
     "start_time": "2021-08-14T05:45:42.044103Z"
    }
   },
   "outputs": [],
   "source": [
    "# combine the results into a list \n",
    "flat_pred_outs = np.concatenate(pred_outs, axis=0)\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-14T05:47:03.103628Z",
     "start_time": "2021-08-14T05:47:03.099667Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert probabilities into 0 or 1 based on a threshold value\n",
    "def classify(pred_prob,thresh_probabilty):\n",
    "     # 0.4 best threshold\n",
    "    # classifies the target as 1 or 0 based on the threshold value 0.5\n",
    "    y_pred = []\n",
    "\n",
    "    for tag_label_row in pred_prob:\n",
    "        temp=[]\n",
    "        for tag_label in tag_label_row:\n",
    "            if tag_label >= thresh_probabilty:\n",
    "                temp.append(1) \n",
    "            else:\n",
    "                temp.append(0)\n",
    "        y_pred.append(temp)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-14T05:47:12.219656Z",
     "start_time": "2021-08-14T05:47:12.214729Z"
    }
   },
   "outputs": [],
   "source": [
    "y_true = flat_true_labels.ravel() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92Sg3rnvYl9P"
   },
   "source": [
    "# Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-14T05:47:32.305267Z",
     "start_time": "2021-08-14T05:47:32.300744Z"
    }
   },
   "outputs": [],
   "source": [
    "# predictions for optimal threshold\n",
    "y_pred_labels = classify(flat_pred_outs,0.4)\n",
    "y_pred = np.array(y_pred_labels).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-O5mB4WP1H97",
    "outputId": "d8f68291-7c8a-4b1b-816f-a2e1c6be3cd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96      3798\n",
      "           1       0.79      0.46      0.59       422\n",
      "\n",
      "    accuracy                           0.93      4220\n",
      "   macro avg       0.87      0.73      0.77      4220\n",
      "weighted avg       0.93      0.93      0.93      4220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "B1LOelIV1LNd",
    "outputId": "f5b5fb31-9f6b-4e53-8f18-eb4dc97138de"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "      <th>Actual Tags</th>\n",
       "      <th>Predicted Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>being new to android development c oop dev i r...</td>\n",
       "      <td>(android,)</td>\n",
       "      <td>(android,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>i was kindly helped by jonathan over here http...</td>\n",
       "      <td>(javascript,)</td>\n",
       "      <td>(javascript,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>my question relates to the underlying renderin...</td>\n",
       "      <td>(java,)</td>\n",
       "      <td>(java,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>when writing javascript i often forget some pr...</td>\n",
       "      <td>(javascript,)</td>\n",
       "      <td>(javascript,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>if this hasclass white console log white equat...</td>\n",
       "      <td>(jquery,)</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>is it possible to call c function from rd part...</td>\n",
       "      <td>(php,)</td>\n",
       "      <td>(php,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>so say i have a file page php html hello php e...</td>\n",
       "      <td>(php,)</td>\n",
       "      <td>(php,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>in my app i want to create something like this...</td>\n",
       "      <td>(android,)</td>\n",
       "      <td>(android,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>typing first time here before i found many hel...</td>\n",
       "      <td>(python,)</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>i have one fragmentactivity that holds viewpag...</td>\n",
       "      <td>(android,)</td>\n",
       "      <td>(android,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Body  ... Predicted Tags\n",
       "66   being new to android development c oop dev i r...  ...     (android,)\n",
       "318  i was kindly helped by jonathan over here http...  ...  (javascript,)\n",
       "198  my question relates to the underlying renderin...  ...        (java,)\n",
       "212  when writing javascript i often forget some pr...  ...  (javascript,)\n",
       "400  if this hasclass white console log white equat...  ...             ()\n",
       "298  is it possible to call c function from rd part...  ...         (php,)\n",
       "280  so say i have a file page php html hello php e...  ...         (php,)\n",
       "296  in my app i want to create something like this...  ...     (android,)\n",
       "365  typing first time here before i found many hel...  ...             ()\n",
       "134  i have one fragmentactivity that holds viewpag...  ...     (android,)\n",
       "\n",
       "[10 rows x 3 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reverses the target encoder \n",
    "y_pred = target_encoder.inverse_transform(np.array(y_pred_labels))\n",
    "y_act = target_encoder.inverse_transform(flat_true_labels)\n",
    "\n",
    "df = pd.DataFrame({'Body':x_test,'Actual Tags':y_act,'Predicted Tags':y_pred})\n",
    "\n",
    "# a sample of how our model would predict tags for 20 questions\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "df.sample(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
